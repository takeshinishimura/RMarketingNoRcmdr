---
title: "Rコマンダーを使わずに『現代マーケティング・リサーチ』を読む"
title-block-banner: true
format:
  html:
    toc: true
    toc-title: 目次
    toc_float: true
    toc-depth: 4
    number-sections: false
    theme: united
    code-fold: false
lang: ja
---

[照井伸彦・佐藤忠彦（2022）『現代マーケティング・リサーチ—市場を読み解くデータ分析 新版』有斐閣](https://www.yuhikaku.co.jp/books/detail/9784641166080){target="_blank"} は，Rを用いたマーケティング・リサーチの入門書として位置づけられる。

本書の想定読者は，Rを初めて使用する学生であり，プログラミングに戸惑うことが予想されるため，Rコマンダーを利用して解説している。
しかし，Rに慣れた読者にとっては，Rコマンダーの処理がブラックボックス化されており，かえって分かりにくい。
そこで，本サイトでは，Rコマンダーによって生成されたコードと，それと同じ処理をRに習熟したユーザーが記述する場合のコードを並べて示し，理解を助ける構成としている。

また，本書にはいくつか誤植があり，本書の指示通りに操作を進めると，Rコマンダーの利用において行き詰まる箇所がある。
そのような部分については適宜修正しながら読み進めることを推奨する。


## 第3章 サンプリング

### 4 単純無作為サンプリング

#### 4.1 Rコマンダーによる乱数表作成

##### ▶ Rコマンダーによって生成されたコード（p. 37）

```{r}
#| eval: false
UniformSamples <- as.data.frame(matrix(runif(1*100, min=0, max=1), ncol=100))
rownames(UniformSamples) <- "sample"
colnames(UniformSamples) <- paste("obs", 1:100, sep="")
```

##### ▶ 手入力するコード（`ransu.R`）

```{r}
#| eval: false
x <- UniformSamples*100
rx <- round(x)+1
ux <- unique(rx)
```

##### ▶ 一般的なRコード

乱数を生成する際に，あらかじめ `set.seed()` を実行しておくと，同じ操作を繰り返したときに同じ乱数を再現できる。
```{r}
set.seed(100)
```
`set.seed()` のかっこ中の数字は何でもよい。

```{r}
ux <- unique(ceiling(runif(100, min = 0, max = 100)))
ux[1:10]
```
または
```{r}
ux <- sample(1:100, 100, replace = FALSE)
ux[1:10]
```

## 第5章 市場反応分析（I）

### 3 相関分析

#### 3.2 売上と価格のデータ：散布図の作成

::: {.callout-warning collapse="false" icon="false"}
## 誤植

p. 84

- （誤）欠損値はないこと“NA”で表している。
- （正）欠損値を“NA”で表すように設定している。

p. 85

- （誤）小数点の記号がピリオドかカンマの指定もできる。
- （正）小数点の記号をピリオドかカンマに指定できる。

p. 86

- （誤）“売上”を選択し，図5.5のようにそれぞれ反転させる。
- （正）“売上”を選択し，図5.5左のようにそれぞれ青色に反転させる。
:::

##### ▶ Rコマンダーによって生成されたコード（p. 84）

```{r}
#| eval: false
Dataset <- read.table(file.choose(), header=TRUE, stringsAsFactors=TRUE, sep="", na.strings="NA", 
  dec=".", strip.white=TRUE)
scatterplot(売上~価格, regLine=FALSE, smooth=FALSE, boxplots=FALSE, data=Dataset)
```

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: false
library(car)

Dataset <- read.table(file.choose(), header = TRUE, sep = "", strip.white = TRUE)
names(Dataset)[1] <- "売上数量"
```
```{r}
#| echo: false
#| message: false
library(car)

Dataset <- read.table("./data/現代マーケティング・リサーチ〔新版〕_ウェブサポートデータ/5/sales-price-promo.txt", header = TRUE, sep = "", strip.white = TRUE)

names(Dataset)[1] <- "売上数量"
```

図5.2の縦軸が「売上数量」となっていたため，列名を変更した。
一般的に「売上」は売上高を指すため，価格と売上の相関関係を図示するのはやや不自然である（価格が上がれば，売上数量が一定の場合，売上高も上昇する）。
この点を踏まえると，本書では図が修正されたものの，本文の修正が反映されないまま出版された可能性があるのではないだろうか。
なお，p. 102の本文では「売上数量」と明確に同じ意味で使わる「売上」の記述が見られる。

```{r}
Dataset
scatterplot(売上数量 ~ 価格, regLine = FALSE, smooth = FALSE, boxplots = FALSE, las = 1, data = Dataset)
```

`scatterplot()` は `car` パッケージの関数であるため，最初に `car` パッケージをロードしている。

次のように汎用的な作図関数 `plot()` を使ってもよい。
この場合，`car` パッケージを読み込む必要はない。
```{r}
plot(売上数量 ~ 価格, data = Dataset, las = 1)
```

#### 3.3 売上と価格に相関はあるか：標本相関係数の検定

##### ▶ Rコマンダーによって生成されたコード（p. 87）

```{r}
#| eval: false
with(Dataset, cor.test(価格, 売上, alternative="two.sided", method="pearson"))
```

##### ▶ 一般的なRコード

```{r}
cor.test(Dataset$価格, Dataset$売上数量, alternative = "two.sided", method = "pearson")
```


### 4 売上と価格の市場反応分析：回帰モデル

##### ▶ Rコマンダーによって生成されたコード（p. 91）

```{r}
#| eval: false
RegModel.1 <- lm(売上~価格, data=Dataset)
summary(RegModel.1)
```

##### ▶ 一般的なRコード

```{r}
RegModel_1 <- lm(売上数量 ~ 価格, data = Dataset)
summary(RegModel_1)
```

昔は変数名（先頭ではなく途中）に `.` が使用されることもあったが，最近は使用しないのが一般的である。

#### 4.1 価格反応係数推定値の精度と信頼区間

##### ▶ Rコマンダーによって生成されたコード（p. 93）

```{r}
#| eval: false
Confint(RegModel.1, level=0.95)
```

##### ▶ 一般的なRコード

```{r}
Confint(RegModel_1, level = 0.95)
```

`Confint()` は `car` パッケージの関数である。


### 5 複数の説明変数を持つ市場反応分析：重回帰モデル

#### 5.1 価格と販売促進の効果

##### ▶ Rコマンダーによって生成されたコード（p. 98）

```{r}
#| eval: false
RegModel.2 <- lm(売上~価格+販促, data=Dataset)
summary(RegModel.2)
```

##### ▶ 一般的なRコード

```{r}
RegModel_2 <- lm(売上数量 ~ 価格 + 販促, data = Dataset)
summary(RegModel_2)
```

::: {.callout-warning collapse="false" icon="false"}
## 誤植

p. 100

- （誤）適合度が0.08程度
- （正）適合度が0.008程度
:::

### 6 弾力性測定モデル

#### 6.1 交差価格弾力性による競合関係の測定

::: {.callout-warning collapse="false" icon="false"}
## 誤植

p. 106

- （誤）売上を【新しい変数名】に“LY”，【計算式】に“log(売上)”と入力する。
- （正）【新しい変数名】に“LY1”，【計算式】に“log(Y1)”と入力する。
:::

##### ▶ Rコマンダーによって生成されたコード（p. 105）

```{r}
#| eval: false
Dataset <- read.table(file.choose(), header=TRUE, stringsAsFactors=TRUE, sep="", na.strings="NA", 
  dec=".", strip.white=TRUE)
Dataset$LY1 <- with(Dataset, log(Y1))
Dataset$LX1 <- with(Dataset, log(X1))
Dataset$LX2 <- with(Dataset, log(X2))
RegModel.3 <- lm(LY1~LX1+LX2, data=Dataset)
summary(RegModel.3)
```

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: false
Dataset <- read.table(file.choose(), header = TRUE, sep = "", strip.white = TRUE)

Dataset$LY1 <- log(Dataset$Y1)
Dataset$LX1 <- log(Dataset$X1)
Dataset$LX2 <- log(Dataset$X2)

RegModel_3 <- lm(LY1 ~ LX1 + LX2, data = Dataset)
summary(RegModel_3)
```
```{r}
#| echo: false
Dataset <- read.table("./data/現代マーケティング・リサーチ〔新版〕_ウェブサポートデータ/5/yogurt.txt", header = TRUE, sep = "", strip.white = TRUE)

Dataset$LY1 <- log(Dataset$Y1)
Dataset$LX1 <- log(Dataset$X1)
Dataset$LX2 <- log(Dataset$X2)

RegModel_3 <- lm(LY1 ~ LX1 + LX2, data = Dataset)
summary(RegModel_3)
```


## 第6章 市場の発見と知覚マップ

### 4 知覚マップの作成

::: {.callout-tip collapse="false" icon="false"}
## 補足情報

本文には，表6.1は「消費者の評価調査データである」とされている。
しかし，同表は実際にはバイヤーに対する調査結果であり，詳細は以下のとおりである。

【調査の方法】  
日本経済新聞社の「小売業調査」の対象になっているスーパー162社に対し，2010年12月22日に調査票をファクスで送付，2011年1月31日までに回収した。
回収数は92社，回収率は56.8%。
調査の実施・分析は日経リサーチが担当した。  
【表中の数字の見方】  
せんべい類を扱うバイヤーに5点満点でメーカーとブランドの総合評価をつけてもらい，その合計得点からランキングを作成した。
採点項目の数字は，メーカーまたはブランドを評価できると回答したバイヤーの割合（%）を表す。  
<div style="text-align: right;">
**（出所：『日経MJ（流通新聞）』2011年2月13日，p. 2）**
</div>
:::

### 5 Rコマンダーでの手順

##### ▶ Rコマンダーによって生成されたコード（p. 119）

```{r}
#| eval: false
Dataset <- read.table("clipboard", header=TRUE, stringsAsFactors=TRUE, sep="¥t", na.strings="NA", 
  dec=".", strip.white=TRUE)
local({
  .FA <- factanal(~キャンペーンイベント+パッケージデザイン+広告宣伝+素材栄養素+味, factors=2, rotation="varimax", scores="regression", data=Dataset)
  print(.FA)
  Dataset <<- within(Dataset, {
    F2 <- .FA$scores[,2]
    F1 <- .FA$scores[,1]
  })
})
scatterplot(F2~F1, regLine=FALSE, smooth=FALSE, id=list(method='identify'), boxplots=FALSE, xlab="マーケティング因子", ylab="製品因子", data=Dataset)
```

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: false
library(car)

Dataset <- read.table("clipboard", header = TRUE, sep = "¥t")

FA <- factanal(
  ~ キャンペーンイベント + パッケージデザイン + 広告宣伝 + 素材栄養素 + 味,
  factors = 2,
  rotation = "varimax",
  scores = "regression",
  data = Dataset
)
print(FA)

Dataset$F1 <- FA$scores[, 1]
Dataset$F2 <- FA$scores[, 2]

rownames(Dataset) <- Dataset$製品名

scatterplot(
  F2 ~ F1,
  data = Dataset,
  regLine = FALSE,
  smooth = FALSE,
  id = list(method = 'identify'),
  boxplots = FALSE,
  xlab = "マーケティング因子",
  ylab = "製品因子"
)
```
```{r}
#| echo: false
#| message: false
library(car)

Dataset <- read.table("./data/現代マーケティング・リサーチ〔新版〕_ウェブサポートデータ/6/senbei.txt", header = TRUE, sep = "\t")

FA <- factanal(~ キャンペーンイベント + パッケージデザイン + 広告宣伝 + 素材栄養素 + 味, factors = 2, rotation = "varimax", scores = "regression", data = Dataset, rownames = 1)
print(FA)

Dataset$F1 <- FA$scores[, 1]
Dataset$F2 <- FA$scores[, 2]

rownames(Dataset) <- Dataset$製品名

scatterplot(
  F2 ~ F1,
  data = Dataset,
  regLine = FALSE,
  smooth = FALSE,
  id = list(method = 'identify'),
  boxplots = FALSE,
  xlab = "マーケティング因子",
  ylab = "製品因子"
)
text(Dataset$F1, Dataset$F2, labels = Dataset$製品名, pos = 4, cex = 1)
```

1つの関数が長い場合は，引数のカンマの後で改行した方が見やすいため，コードを書く際に改行を入れるのが一般的である。
このとき，改行した行の先頭にはスペースを2つ入れる。

なお，クリップボードからデータを読むコードはOSによって異なる。
上に示したコードはWindowsの場合であり，macOSの場合，`Dataset <- read.csv(pipe("pbpaste"), header = TRUE, sep = "\t")` とする。
タブを表す記号 `¥t` はWindowsの場合であり，macOSでは `\t` である。
ここで，`read.table()` の代わりに，`read.delim()` を使うこともできる。
`read.delim()` を使う場合は，引数の `header` と `sep` を省略できる（デフォルト値のため）。

また，Rコマンダーでは因子分析の結果を `.FA` に代入している。
`.` で始まる変数名はユーザーから隠す意図があり，この場面では意図通りに変数名を用いている（ただし，`local()` を使っているため，`.` で始まる必要はないのではあるが…）。
ここでは，ユーザーから隠す必然性はないため，`.FA` の代わりに `FA` という変数名を一般的なRコードで用いた。

さらに，本文の指示通りだと，図6.6の知覚マップには製品名ではなく，データフレーム `Dataset` の行番号が表示されることになる。
知覚マップ上に製品名を表示するには，`rownames(Dataset) <- Dataset$製品名` を追加するか，あるいは，`read.csv()` の引数に `row.names = 1` を指定する必要がある，

### 6 その他の問題

#### 6.2 共通因子数の設定

##### ▶ Rコマンダーによって生成されたコード（p. 84）

```{r}
#| eval: false
local({
  .PC <- princomp(~キャンペーンイベント+パッケージデザイン+広告宣伝+素材栄養素+味, cor=TRUE, data=Dataset)
  cat("\nComponent loadings:\n")
  print(unclass(loadings(.PC)))
  cat("\nComponent variances:\n")
  print(.PC$sd^2)
  cat("\n")
  print(summary(.PC))
  screeplot(.PC)

})
```

##### ▶ 一般的なRコード

```{r}
PC <- princomp( ~ キャンペーンイベント + パッケージデザイン + 広告宣伝 + 素材栄養素 + 味, cor = TRUE, data = Dataset)

result <- list(
  "Component Loadings" = unclass(loadings(PC)),
  "Component Variances" = PC$sd ^ 2,
  "Summary" = summary(PC)
)

result

screeplot(PC)
screeplot(PC, type = "lines")
```

スクリープロットを描く際，`screeplot(PC)` の引数として `type = "lines"` を指定すると折れ線グラフになり，こちらが一般的に用いられる。

また，主成分分析を使わずに相関行列の固有値を計算し，スクリープロットを描く方法もある。
因子分析の際にはこの方法が使われることがある。
```{r}
cor_matrix <- cor(Dataset[, c("キャンペーンイベント", "パッケージデザイン", "広告宣伝", "素材栄養素", "味")])
ev <- eigen(cor_matrix)$values

plot(ev, type = "b", main = "スクリープロット", xlab = "因子数", ylab = "固有値", pch = 19)
abline(h = 1, col = "red", lty = 2)
```

さらに，`psych` パッケージには簡単にスクリープロットを描く関数が用意されている。
```{r}
#| eval: false
library(psych)

fa.parallel(cor_matrix, n.obs = nrow(Dataset), fa = "fa")
```
```{r}
#| echo: false
#| message: false
library(psych)

fa.parallel(cor_matrix, n.obs = nrow(Dataset), fa = "fa")
```

`fa.parallel()` は，単なる固有値のプロットではなく，実データの固有値とランダムデータから計算された固有値を比較するものである。

### 7 サブマーケットと市場構造

##### ▶ Rコマンダーによって生成されたコード（p. 84）

```{r}
#| eval: false
HClust.1 <- hclust(dist(model.matrix(~-1 + F1+F2, Dataset)) , method= "ward")
plot(HClust.1, main= "Cluster Dendrogram for Solution HClust.1", xlab= "Observation Number in Data Set Dataset", sub="Method=ward; Distance=euclidian")
```

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: true
dist_1 <- dist(Dataset[, c("F1", "F2")], method = "euclidean")
HClust_1 <- hclust(dist_1, method = "ward.D2")

plot(
  HClust_1,
  main = "Cluster Dendrogram for Solution HClust_1",
  xlab = "Observation Number in Data Set Dataset",
  sub = "Method=ward.D2; Distance=euclidean"
)
```

ウォード法は `ward` や `ward.D` ではなく，`ward.D2` を指定する。
詳細な説明は関数 `hclust()` の[ヘルプ](https://stat.ethz.ch/R-manual/R-patched/library/stats/html/hclust.html){target="_blank"}を参照のこと。

なお，知覚マップのところで `rownames(Dataset) <- Dataset$製品名` を追加した場合は，図6.9とは異なり，デンドログラムに製品名が表示される。
製品名ではなく番号を使ってデンドログラムを描くには，次のコードを実行する。
```{r}
#| echo: true
#| eval: true
rownames(Dataset) <- 1:nrow(Dataset)

dist_1 <- dist(Dataset[, c("F1", "F2")], method = "euclidean")
HClust_1 <- hclust(dist_1, method = "ward.D2")

plot(
  HClust_1,
  main = "Cluster Dendrogram for Solution HClust_1",
  xlab = "Observation Number in Data Set Dataset",
  sub = "Method=ward.D2; Distance=euclidean"
)
```

以下は，図6.10の作図のためのコードである。
なお，クラスター分析に `ward.D2` を使用しているため，クラスター間距離が本書の記述とは異なる。
```{r}
#| warning: false
Dataset$Cluster <- as.factor(cutree(HClust_1, h = 3))

par(mfrow = c(1, 2))

plot(
  Dataset$F1, Dataset$F2,
  col = as.numeric(Dataset$Cluster),
  pch = 16,
  xlab = "マーケティング因子", ylab = "製品因子",
  main = "クラスター間距離3"
)

text(Dataset$F1, Dataset$F2, labels = Dataset$製品名, pos = 4, cex = 1)

for (k in unique(Dataset$Cluster)) {
  dataEllipse(
    Dataset$F1[Dataset$Cluster == k],
    Dataset$F2[Dataset$Cluster == k],
    add = TRUE, col = k, lty = 2,
    levels = 0.5)
}

Dataset$Cluster <- as.factor(cutree(HClust_1, h = 1))

plot(
  Dataset$F1, Dataset$F2,
  col = as.numeric(Dataset$Cluster),
  pch = 16,
  xlab = "マーケティング因子", ylab = "製品因子",
  main = "クラスター間距離1"
)

text(Dataset$F1, Dataset$F2, labels = Dataset$製品名, pos = 4, cex = 1)

for (k in unique(Dataset$Cluster)) {
  cluster_data <- Dataset[Dataset$Cluster == k, c("F1", "F2")]

  if (nrow(cluster_data) > 1) {
    dataEllipse(
      cluster_data$F1,
      cluster_data$F2,
      add = TRUE, col = k, lty = 2,
      levels = 0.5)
  }
}
```

`dataEllipse()` はデータのばらつきをもとに楕円を描くため，2点しかないと警告が出て，直線が描かれる点に注意が必要である。

図を横に並べて表示する設定を行ったため，次のコードを実行してデフォルトの設定に戻しておく。
```{r}
par(mfrow = c(1, 1))
```


## 第7章 市場セグメンテーション

### 5 Rコマンダーによる市場セグメンテーション

#### 5.2 因子分析

::: {.callout-warning collapse="false" icon="false"}
## 誤植

p. 153

誤植というより，おそらく `Rcmdr` のバージョン違いにより，出力結果が異なっている可能性がある。図7.8，図7.9の通り実行しても，エラーになってしまう。以下の「手入力するコード」の部分を実行すると，本書の意図通りになるはずである（1行目のエラーは避けられない）。
:::

##### ▶ Rコマンダーによって生成されたコード（p. 149）

```{r}
#| eval: false
Dataset <- read.table(file.choose(), header=TRUE, stringsAsFactors=TRUE, sep=",", na.strings="NA", 
  dec=".", strip.white=TRUE)
local({
  .FA <- factanal(~q1+q2+q3+q4+q5+q6+q7+q8+q9+q10+q11+q12+q13+q14+q15+q16+q17+q18+q19+q20+q21+q22+q23+q24+q25+q26+q27, factors=4, 
  rotation="varimax", scores="regression", data=Dataset)
  print(.FA)
  Dataset <<- within(Dataset, {
    F4 <- .FA$scores[,4]
    F3 <- .FA$scores[,3]
    F2 <- .FA$scores[,2]
    F1 <- .FA$scores[,1]
  })
})
```

##### ▶ 手入力するコード

```{r}
#| eval: false
remove(.FA)
.FA <- factanal(~q1+q2+q3+q4+q5+q6+q7+q8+q9+q10+q11+q12+q13+q14+q15+q16+q17+q18+q19+q20+q21+q22+q23+q24+q25+q26+q27, factors=4, rotation="varimax", scores="regression", data=Dataset)
.FA
Dataset$FA1 <- .FA$scores[,1]
Dataset$FA2 <- .FA$scores[,2]
Dataset$FA3 <- .FA$scores[,3]
Dataset$FA4 <- .FA$scores[,4]
print(.FA,cutoff=0,sort=TRUE)
```

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: false
Dataset <- read.csv(file.choose())

FA <- factanal(
  ~ q1 + q2 + q3 + q4 + q5 + q6 + q7 + q8 + q9 + q10 + q11 + q12 + q13 + q14 + q15 + q16 + q17 + q18 + q19 + q20 + q21 + q22 + q23 + q24 + q25 + q26 + q27,
  factors = 4,
  rotation = "varimax",
  scores = "regression",
  data = Dataset
)
print(FA)
```
```{r}
#| echo: false
#| message: false
Dataset <- read.csv("./data/現代マーケティング・リサーチ〔新版〕_ウェブサポートデータ/7/seg.txt")

FA <- factanal(
  ~ q1 + q2 + q3 + q4 + q5 + q6 + q7 + q8 + q9 + q10 + q11 + q12 + q13 + q14 + q15 + q16 + q17 + q18 + q19 + q20 + q21 + q22 + q23 + q24 + q25 + q26 + q27,
  factors = 4,
  rotation = "varimax",
  scores = "regression",
  data = Dataset
)
print(FA)
```
```{r}
Dataset$F1 <- FA$scores[, 1]
Dataset$F2 <- FA$scores[, 2]
Dataset$F3 <- FA$scores[, 3]
Dataset$F4 <- FA$scores[, 4]

print(FA, cutoff = 0, sort = TRUE)
```

#### 5.3 クラスター分析

::: {.callout-warning collapse="false" icon="false"}
## 誤植

p. 153

- （誤）入力としてF1〜F4（【変数（1つ以上選択）】）を指定し，クラスター数は4つとした。
- （正）入力としてF1〜F4（【変数（1つ以上選択）】）を指定し，クラスター数は4つとした。さらに，【オプション】タブでは「データセットにクラスタを割り当てる」にチェックを入れる。最後に，【OK】をクリックする。
:::

##### ▶ Rコマンダーによって生成されたコード（p. 153）

```{r}
#| eval: false
.cluster <-  KMeans(model.matrix(~-1 + F1 + F2 + F3 + F4, Dataset), centers = 4, iter.max = 10, num.seeds = 10)
.cluster$size # Cluster Sizes
.cluster$centers # Cluster Centroids
.cluster$withinss # Within Cluster Sum of Squares
.cluster$tot.withinss # Total Within Sum of Squares
.cluster$betweenss # Between Cluster Sum of Squares
biplot(princomp(model.matrix(~-1 + F1 + F2 + F3 + F4, Dataset)), xlabs = as.character(.cluster$cluster))
Dataset$KMeans <- assignCluster(model.matrix(~-1 + F1 + F2 + F3 + F4, Dataset), Dataset, .cluster$cluster)
remove(.cluster)
local({
  .Table <- with(Dataset, table(KMeans))
  cat("\ncounts:\n")
  print(.Table)
  cat("\npercentages:\n")
  print(round(100*.Table/sum(.Table), 2))
})
library(abind, pos=16)
library(e1071, pos=17)
numSummary(Dataset[,c("F1", "F2", "F3", "F4"), drop=FALSE], groups=Dataset$KMeans, statistics=c("mean"), quantiles=c(0,.25,.5,.75,1))
```

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: true
set.seed(10)

cluster <- kmeans(Dataset[, c("F1", "F2", "F3", "F4")], centers = 4, iter.max = 10, nstart = 10)

result <- list(
  "Cluster Sizes" = cluster$size,
  "Cluster Centroids" = cluster$centers,
  "Within Cluster Sum of Squares" = cluster$withinss,
  "Total Within Sum of Squares" = cluster$tot.withinss,
  "Between Cluster Sum of Squares" = cluster$betweenss
)

result
```

主成分分析のバイプロットを描画し，データポイントを _K-means_ 法によるクラスター分析の結果に基づいてラベル付けする。
```{r}
biplot(princomp(Dataset[, c("F1", "F2", "F3", "F4")]), xlabs = as.character(cluster$cluster))
```

_K-means_ 法によるクラスター分析の結果を確認する。
```{r}
Dataset$KMeans <- cluster$cluster

table(Dataset$KMeans)
round(prop.table(table(Dataset$KMeans)) * 100, 2)
split_data <- split(Dataset[, c("F1", "F2", "F3", "F4")], Dataset$KMeans)

result <- data.frame(セグメント = names(split_data),
                     t(sapply(split_data, colMeans)),
                     サンプルサイズ = sapply(split_data, nrow))
result
```

`result` の出力結果において，行の並び順が表7.9と異なっていても問題ない。

#### 5.4 セグメントのプロファイリング

表7.10〜表7.13もRを使って作成できる。
```{r}
split_data <- split(Dataset, Dataset$KMeans)

gender <- round(prop.table(sapply(split_data, function(df) table(df$性別)), margin = 2) * 100, 1)
gender_table <- data.frame(セグメント = names(split_data), t(gender))
names(gender_table)[-1] <- c("男性", "女性")

gender_table

data.frame(セグメント = names(split_data),
           平均年齢 = sapply(split_data, function(df) round(mean(df$年齢), 1)))

data.frame(セグメント = names(split_data),
           投資経験年数 = sapply(split_data, function(df) round(mean(df$投資経験年数), 1)))

transaction <- round(prop.table(sapply(split_data, function(df) table(df$取引形態)), margin = 2) * 100, 1)
transaction_table <- data.frame(セグメント = names(split_data), t(transaction))
names(transaction_table)[-1] <- c("対面取引", "インターネット取引", "対面とインターネットの併用")

transaction_table
```

さらに，図7.4もRを使って作成できる。
```{r}
gender_counts <- table(Dataset$性別)
names(gender_counts) <- c("男性", "女性") 

barplot(gender_counts)

Dataset$年齢区分 <- cut(Dataset$年齢, 
                       breaks = seq(20, max(Dataset$年齢) + 5, by = 5), 
                       right = FALSE)

barplot(table(Dataset$年齢区分), col = "skyblue", las = 2)
```

細かい調整が必要な場合は，自分でカスタマイズ可能である。
例えば，棒グラフの上に数値を表示したい場合は，次のようにする。
```{r}
bar_positions <- barplot(gender_counts, ylim = c(0, max(gender_counts) * 1.2), col = adjustcolor(c("blue", "red"), alpha.f = .5))
text(bar_positions, gender_counts, labels = gender_counts, pos = 3, cex = 1, col = "black")
```


## 第8章 製品開発

### 4 コンジョイント分析

#### 4.2 個人分析：Rコマンダーによる分析

::: {.callout-warning collapse="false" icon="false"}
## 誤植

p. 173

- （誤）日本語処理の関係で先頭に `X` が付いている
- （正）デフォルトでは，数字で始まる列名の先頭に `X` が付く
:::

##### ▶ Rコマンダーによって生成されたコード（p. 172）

```{r}
#| eval: false
Dataset <- read.table(file.choose(), header=TRUE, stringsAsFactors=TRUE, sep="", na.strings="NA", 
  dec=".", strip.white=TRUE)
RegModel.1 <- lm(全体効用~X2年+X4時間+X6時間+シルバー+赤, data=Dataset)
summary(RegModel.1)
```

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: false
Dataset <- read.table(file.choose(), header = TRUE, sep = "")

RegModel_1 <- lm(全体効用 ~ X2年 + X4時間 + X6時間 + シルバー + 赤, data = Dataset)
summary(RegModel_1)
```
```{r}
#| echo: false
#| message: false
Dataset <- read.table("./data/現代マーケティング・リサーチ〔新版〕_ウェブサポートデータ/8/conjoint1.txt", header = TRUE, sep = "")

RegModel_1 <- lm(全体効用 ~ X2年 + X4時間 + X6時間 + シルバー + 赤, data = Dataset)
summary(RegModel_1)
```

`conjoint1.txt` はタブ区切りテキストのように見えるが，Rコマンダーで「フィールドの区切り記号」を「タブ」にするとエラーが出て読み込めない。
「空白」にすると読み込める。
よく見ると，`conjoint1.txt` のヘッダーのみスペース区切りになっている。
このようなデータは珍しい。

なお，数字で始まる列名の先頭に `X` を付けたくない場合は，`read.table()` の引数に `check.names = FALSE` を指定すればよい。
```{r}
#| echo: true
#| eval: false
Dataset <- read.table(file.choose(), header = TRUE, sep = "", check.names = FALSE)
Dataset
```
```{r}
#| echo: false
Dataset <- read.table("./data/現代マーケティング・リサーチ〔新版〕_ウェブサポートデータ/8/conjoint1.txt", header = TRUE, sep = "", check.names = FALSE)
Dataset
```

ただし，`lm()` を実行するときには，列名をバッククオート ``` ` ``` で括る必要がある。
```{r}
RegModel_1 <- lm(全体効用 ~ `2年` + `4時間` + `6時間` + シルバー + 赤, data = Dataset)
summary(RegModel_1)
```

実際に自分でデータを扱う際には，こうしたことを考慮しながら，列名をどうするかを決める必要がある。

### 5 直交表利用によるコンジョイント分析

#### 5.3 集計分析：Rコマンダーによる分析

##### ▶ Rコマンダーによって生成されたコード（p. 179）

```{r}
#| eval: false
Dataset <- read.table(file.choose(), header=TRUE, stringsAsFactors=TRUE, sep="", na.strings="NA", 
  dec=".", strip.white=TRUE)
RegModel.2 <- lm(全体効用~X2年+X4時間+X6時間+シルバー+赤, data=Dataset)
summary(RegModel.2)
```

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: false
Dataset <- read.table(file.choose(), header = TRUE, sep = "")

RegModel_2 <- lm(全体効用 ~ X2年 + X4時間 + X6時間 + シルバー + 赤, data = Dataset)
summary(RegModel_2)
```
```{r}
#| echo: false
Dataset <- read.table("./data/現代マーケティング・リサーチ〔新版〕_ウェブサポートデータ/8/conjoint2.txt", header = TRUE, sep = "")

RegModel_2 <- lm(全体効用 ~ X2年 + X4時間 + X6時間 + シルバー + 赤, data = Dataset)
summary(RegModel_2)
```

`conjoint2.txt` も `conjoint1.txt` と同様に変わったルール（ヘッダーのみスペース区切りで，他はタブ区切り）でデータが記述されている。


## 第9章 新製品の普及

### 6 Rコマンダーによる新製品普及構造の分析

#### 6.1 回帰分析

::: {.callout-warning collapse="false" icon="false"}
## 誤植

p. 202，表9.2

- （誤）5000e+03
- （正）5.000e+03

p. 203

- （誤）予測値が追加される。本書の検証は
- （正）予測値が追加される。その後，【グラフ】⇒【折れ線グラフ…】でコマンドボックスを立ち上げて，【x 変数（1つ選択）】から「時点」を選択し，【y 変数（2つ以上選択）】から「購買者数」と「予測」を選択した後で，【OK】をクリックする。本書の検証は
:::

##### ▶ Rコマンダーによって生成されたコード（p. 199）

```{r}
#| eval: false
Dataset <- read.table(file.choose(), header=TRUE, stringsAsFactors=TRUE, sep=",", na.strings="NA", 
  dec=".", strip.white=TRUE)
Dataset2 <- subset(Dataset, subset=時点<11)
RegModel.1 <- lm(購買者数~一期前累積購買者数+一期前累積購買者数の二乗, data=Dataset2)
summary(RegModel.1)
```

##### ▶ 手入力するコード

```{r}
#| eval: true
a <- 5.000e+03
b <- 9.983e-02
c <- -3.994e-06

m <- (- b - sqrt(b ^ 2 - 4 * a * c)) / (2 * c)
p <- a / m
q <- p + b
m
p
q
```

本書の指示通りに計算すると，`p` と `q` は小数第4位で四捨五入すれば正しい値が計算できたことになる。
ただし，`m` については四捨五入したとしても値が一致しない。

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: false
Dataset <- read.csv(file.choose(), header = TRUE)

Dataset2 <- Dataset[Dataset$時点 < 11, ]

RegModel_1 <- lm(購買者数 ~ 一期前累積購買者数 + I(一期前累積購買者数 ^ 2), data = Dataset2)
summary(RegModel_1)
```
```{r}
#| echo: false
#| message: false
Dataset <- read.csv("./data/現代マーケティング・リサーチ〔新版〕_ウェブサポートデータ/9/Bass.txt", header = TRUE)

Dataset2 <- Dataset[Dataset$時点 < 11, ]

RegModel_1 <- lm(購買者数 ~ 一期前累積購買者数 + I(一期前累積購買者数 ^ 2), data = Dataset2)
summary(RegModel_1)
```

このデータについて，「累積購買者数」，「一期前累積購買者数」，「一期前累積購買者数の二乗」の3つの列がどこで計算されたのかが気になる。
通常は，次のデータが手元にあると考えるのが理に適っているだろう。
```{r}
Dataset <- Dataset[, 1:2]
Dataset
```

このデータから，必要なデータを作成可能である。
```{r}
Dataset$累積購買者数 <- cumsum(Dataset$購買者数)
Dataset$一期前累積購買者数 <- c(0, head(Dataset$累積購買者数, -1))
Dataset$一期前累積購買者数の二乗 <- Dataset$一期前累積購買者数 ^ 2
Dataset
```

続いて，`m`，`p`，`q` の計算は，`lm()` の結果を用いて計算することができる。
```{r}
x <- coef(RegModel_1)
names(x) <- NULL
a <- x[1]
b <- x[2]
c <- x[3]

m <- (- b - sqrt(b ^ 2 - 4 * a * c)) / (2 * c)
p <- a / m
q <- p + b
m
p
q
```

今度は，本書と同じ値が計算された。
続いて，図9.12を作成する。

##### ▶ Rコマンダーによって生成されたコード（p. 203）

```{r}
#| eval: false
Dataset$予測 <- with(Dataset, 5.000e+03+一期前累積購買者数*9.983e-02+一期前累積購買者数の二乗*(-3.994e-06))
with(Dataset, lineplot(時点, 購買者数, 予測))
```

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: true
Dataset$予測 <- as.matrix(cbind(1, Dataset[, c("一期前累積購買者数", "一期前累積購買者数の二乗")])) %*% coef(RegModel_1)
```

このとき， `predict()` 関数を使うと便利である。
```{r}
#| eval: false
Dataset$予測 <- predict(RegModel_1, newdata = Dataset)
```

Rコマンダーでは，`RcmdrMisc` パッケージの関数 `lineplot()` で作図しているので，Rコマンダーを使わない場合はこの関数は使えない。
代わりに，次のコードで図を作成できる。
```{r}
plot(Dataset$時点, Dataset$購買者数, type = "l", col = "black", lwd = 2,
     ylim = range(c(Dataset$購買者数, Dataset$予測)),
     xlab = "時点", ylab = "", main = "購買者数と予測値の推移")
lines(Dataset$時点, Dataset$予測, col = "red", lwd = 2, lty = 2)
text(Dataset$時点, Dataset$購買者数, labels = "1", pos = 3, offset = -.5, col = "black")
text(Dataset$時点, Dataset$予測, labels = "2", pos = 3, offset = -.5, col = "red")
legend("topright", legend = c("購買者数", "予測"), col = c("black", "red"), lty = c(1, 2), lwd = 2)
```

図9.13にあるような累積購入者数のグラフを作成するには，次のコードを実行する。
```{r}
plot(累積購買者数 ~ 時点, data = Dataset, type = "l", col = "black", lwd = 2, las = 1, ylim = c(0, max(Dataset$累積購買者数)), main = "普及パターン")
```


## 第10章 顧客の管理

### 4 Rコマンダーによる顧客管理のための分析

#### 4.1 RFM分析

##### ▶ Rコマンダーによって生成されたコード（p. 220）

```{r}
#| eval: false
Dataset <- read.table(file.choose(), header=TRUE, stringsAsFactors=TRUE, sep=",", na.strings="NA", 
  dec=".", strip.white=TRUE)
Dataset <- within(Dataset, {
  M_Rank <- Recode(M, '0:49999="M_Rank1"; 50000:99999="M_Rank2"; 100000:299999="M_Rank3"; 300000:499999="M_Rank4"; else="M_Rank5"', 
  as.factor=TRUE, to.value="=", interval=":", separator=";")
})
Dataset <- within(Dataset, {
  F_Rank <- Recode(F, '1="F_Rank1"; 2="F_Rank2"; 3:9="F_Rank3"; 10:29="F_Rank4"; else="F_Rank5";', as.factor=TRUE, to.value="=", 
  interval=":", separator=";")
})
Dataset <- within(Dataset, {
  R_Rank <- Recode(R, '0:30="R_Rank5"; 31:60="R_Rank4"; 61:90="R_Rank3"; 91:180="R_Rank2"; else="R_Rank1"; ;', as.factor=TRUE, 
  to.value="=", interval=":", separator=";")
})
Boxplot(M ~ R_Rank, data=Dataset, id=list(method="y"))
Boxplot(F ~ R_Rank, data=Dataset, id=list(method="y"))
library(mvtnorm, pos=16)
library(survival, pos=16)
library(MASS, pos=16)
library(TH.data, pos=16)
library(multcomp, pos=16)
library(abind, pos=21)
AnovaModel.2 <- aov(M ~ R_Rank, data=Dataset)
summary(AnovaModel.2)
with(Dataset, numSummary(M, groups=R_Rank, statistics=c("mean", "sd")))
local({
  .Pairs <- glht(AnovaModel.2, linfct = mcp(R_Rank = "Tukey"))
  print(summary(.Pairs)) # pairwise tests
  print(confint(.Pairs, level=0.95)) # confidence intervals
  print(cld(.Pairs, level=0.05)) # compact letter display
  old.oma <- par(oma=c(0, 5, 0, 0))
  plot(confint(.Pairs))
  par(old.oma)
})
```

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: false
Dataset <- read.csv(file.choose(), header = TRUE)

Dataset$M_Rank <- cut(
  Dataset$M,
  breaks = c(-Inf, 49999, 99999, 299999, 499999, Inf),
  labels = paste0("M_Rank", 1:5),
  right = TRUE
)
Dataset$F_Rank <- cut(
  Dataset$F,
  breaks = c(-Inf, 1, 2, 9, 29, Inf),
  labels = paste0("F_Rank", 1:5),
  right = TRUE
)
Dataset$R_Rank <- cut(
  Dataset$R,
  breaks = c(-Inf, 30, 60, 90, 180, Inf),
  labels = paste0("R_Rank", 5:1),
  right = TRUE
)
Dataset$R_Rank <- factor(Dataset$R_Rank, levels = rev(levels(Dataset$R_Rank)))
```
```{r}
#| echo: false
#| eval: true
Dataset <- read.csv("./data/現代マーケティング・リサーチ〔新版〕_ウェブサポートデータ/10/RFM.txt", header = TRUE)

Dataset$M_Rank <- cut(
  Dataset$M,
  breaks = c(-Inf, 49999, 99999, 299999, 499999, Inf),
  labels = paste0("M_Rank", 1:5),
  right = TRUE
)
Dataset$F_Rank <- cut(
  Dataset$F,
  breaks = c(-Inf, 1, 2, 9, 29, Inf),
  labels = paste0("F_Rank", 1:5),
  right = TRUE
)
Dataset$R_Rank <- cut(
  Dataset$R,
  breaks = c(-Inf, 30, 60, 90, 180, Inf),
  labels = paste0("R_Rank", 5:1),
  right = TRUE
)
Dataset$R_Rank <- factor(Dataset$R_Rank, levels = rev(levels(Dataset$R_Rank)))
```

`Boxplot()` は `car` パッケージの関数である。
`car` パッケージを使わなくても，`boxplot()` で同じ図が作成できる。
```{r}
boxplot(M ~ R_Rank, data = Dataset, col = "gray")
boxplot(F ~ R_Rank, data = Dataset, col = "gray")

AnovaModel_2 <- aov(M ~ R_Rank, data = Dataset)
summary(AnovaModel_2)
```

Rコマンダーでは，`RcmdrMisc` パッケージの関数 `lineplot()` でTukeyのHSD検定を行っているので，Rコマンダーを使わない場合はこの関数は使えない。
代わりに，次のコードで同様の結果が得られる。
```{r}
#| echo: true
#| eval: true
mean <- tapply(Dataset$M, Dataset$R_Rank, mean)
sd <- tapply(Dataset$M, Dataset$R_Rank, sd)
data.frame(R_Rank = names(mean), mean = mean, sd = sd)

Tukey_Result <- TukeyHSD(AnovaModel_2, "R_Rank")
Tukey_Result
plot(Tukey_Result)

library(multcompView)

tukey_pvalues <- Tukey_Result$R_Rank[, "p adj"]
cld_results <- multcompLetters(tukey_pvalues)
cld_results
```

#### 4.2 ロジスティック回帰分析

::: {.callout-warning collapse="false" icon="false"}
## 誤植

p. 226

- （誤）一般化線形モデル
- （正）一般化線型モデル

これはRコマンダーの翻訳ミスであろう。同様の翻訳ミスはこの箇所以降にも見られる。
:::

##### ▶ Rコマンダーによって生成されたコード（p. 220）

```{r}
#| eval: false
GLM.3 <- glm(DM ~ log(M)+log(F)+log(R), family=binomial(logit), data=Dataset)
summary(GLM.3)
exp(coef(GLM.3))  # Exponentiated coefficients ("odds ratios")
```

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: true
Dataset$DM <- factor(Dataset$DM, levels = c("no", "yes"))
# Dataset$DM01 <- ifelse(Dataset$DM == "yes", 1, 0)

GLM.3 <- glm(DM ~ log(M) + log(F) + log(R), family = binomial(logit), data = Dataset)
summary(GLM.3)
exp(coef(GLM.3))
```

Rコマンダーは，どうやら内部で `DM` 列をファクターに変換しているようである。
実際には，`factor()` を適用するか，`ifelse()` でダミー変数に変換すればよい。
ダミー変数に変換した場合は，値も変わってしまうため，列名を変更することを推奨する。


## 第11章 市場反応分析（II）

### 3 Rコマンダーによる分析

#### 3.1 ブランド価値を含むモデル

```{r}
#| eval: false
Dataset <- read.table(file.choose(), header=TRUE, stringsAsFactors=TRUE, sep="", na.strings="NA", 
  dec=".", strip.white=TRUE)
GLM.1 <- glm(B1 ~ P1-P2, family=binomial(logit), data=Dataset)
summary(GLM.1)
exp(coef(GLM.1))  # Exponentiated coefficients ("odds ratios")
GLM.2 <- glm(B1 ~ P1 - P2, family=binomial(probit), data=Dataset)
summary(GLM.2)
```

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: false
Dataset <- read.table(file.choose(), header = TRUE, sep = "", strip.white = TRUE)

GLM_1 <- glm(B1 ~ P1 - P2, family = binomial(logit), data = Dataset)
summary(GLM_1)
```
```{r}
#| echo: false
#| message: false
Dataset <- read.table("./data/現代マーケティング・リサーチ〔新版〕_ウェブサポートデータ/11/binomial-choice.txt", header = TRUE, sep = "", strip.white = TRUE)

GLM_1 <- glm(B1 ~ P1 - P2, family = binomial(logit), data = Dataset)
summary(GLM_1)
```
```{r}
exp(coef(GLM_1))
GLM_2 <- glm(B1 ~ P1 - P2, family = binomial(probit), data = Dataset)
summary(GLM_2)
```

`binomial-choice.txt` もヘッダーのみスペース区切りで，データはタブ区切りになっている。
タブ区切りのデータはヘッダーもタブ区切りであるのが普通であり，本書で扱うデータが特殊であることを認識しておく必要がある。

##### ▶ Rコマンダーによって生成されたコード（p. 240）

```{r}
#| eval: false
GLM.3 <- glm(B1 ~ 0+P1 - P2, family=binomial(logit), data=Dataset)
summary(GLM.3)
exp(coef(GLM.3))  # Exponentiated coefficients ("odds ratios")
```

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: true
GLM_3 <- glm(B1 ~ 0 + P1 - P2, family = binomial(logit), data = Dataset)
summary(GLM_3)
exp(coef(GLM_3))
```

### 4 多項離散選択モデル

#### 4.1 Rによる分析：多項ロジット・モデルの推定

##### ▶ Rコマンダーによって生成されたコード（p. 241）

```{r}
#| eval: false
library(mlogit, pos=16)
data(Catsup, package="mlogit")
```

##### ▶ 手入力するコード（`mlogit.R`）

```{r}
#| eval: false
library(mlogit)
data(Catsup)
Catdata <- mlogit.data(Catsup, choice = "choice", shape = "wide", varying = c(2:13), sep=".")
Cat1<-mlogit(choice ~ disp+feat+price , data = Catdata)
summary(Cat1)
```

##### ▶ 一般的なRコード

`mlogit` パッケージをインストールしたことがなければ，最初に次のコードを実行する。
```{r}
#| eval: false
install.packages("mlogit")
```

その後，次のコードを実行する。
```{r}
#| echo: true
#| eval: true
#| message: false
library(mlogit)

data(Catsup)

Catdata <- mlogit.data(Catsup, choice = "choice", shape = "wide", varying = c(2:13), sep = ".")

Cat1 <- mlogit(choice ~ disp + feat + price , data = Catdata)
summary(Cat1)
```


## 第12章 ブランドと属性の同時マップ

### 1 質的変数の関連性

#### 1.2 Rコマンダーによる質的変数の独立性の検定

##### ▶ Rコマンダーによって生成されたコード（p. 251）

```{r}
#| eval: false
library(abind, pos=16)
.Table <- matrix(c(75,80,145,125,90,85), 2, 3, byrow=TRUE)
dimnames(.Table) <- list("地域"=c("1", "2"), "嗜好"=c("1", "2", "3"))
.Table  # Counts
.Test <- chisq.test(.Table, correct=FALSE)
.Test
.Test$expected # Expected Counts
round(.Test$residuals^2, 2) # Chi-square Components
remove(.Test)
remove(.Table)
```

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: true
Table <- matrix(c(75, 80, 145, 125, 90, 85), nrow = 2, ncol = 3, byrow = TRUE)
dimnames(Table) <- list("地域" = c("1", "2"), "嗜好" = c("1", "2", "3"))
Table

Test <- chisq.test(Table, correct = FALSE)
Test

Test$expected

round(Test$residuals ^ 2, 2)
```

### 3 Rコマンダーによるコレスポンデンス分析

#### 3.1 実行手順

::: {.callout-warning collapse="false" icon="false"}
## 誤植

p. 256

- （誤）次にRコマンダーウィンドウのツールバー【ツール】⇒【Rcmdrプラグインのロード】へ進むと「RcmdrPlugin. FactoMineR」の選択画面が現れ，【OK】をクリックして選択する。
- （正）インストール後，一度Rコマンダーを終了し，Rも終了する。その後，再び，RとRコマンダーを起動する。次にRコマンダーウィンドウのツールバー【ツール】⇒【Rcmdrプラグインのロード】へ進むと「RcmdrPlugin.FactoMineR」の選択画面が現れ，【OK】をクリックして選択する。

p. 257

- （誤）Perform clustring on
- （正）Perform clustering on

p. 257

- （誤）“iterative”をを選択
- （正）“interactive”を選択
:::

プラグイン `RcmdrPlugin.FactoMineR` をインストールしたことがなければ，最初に次のコードを実行する。
```{r}
#| eval: false
install.packages("RcmdrPlugin.FactoMineR")
```
なお，Rコマンダーを使わない場合は，このプラグインのインストールは不要である。

##### ▶ Rコマンダーによって生成されたコード（p. 256）

```{r}
#| eval: false
Dataset <- read.table(file.choose(), header=TRUE, stringsAsFactors=TRUE, sep="", na.strings="NA", 
  dec=".", strip.white=TRUE)
Dataset.CA<-Dataset[c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10") ,c("デザイン", "使いやすさ", "パワー", "静音性", "サイズ", "手入れのしやすさ", "取り回し",
   "満足度")]
res<-CA(Dataset.CA, ncp=5, row.sup=NULL, col.sup=NULL, graph = FALSE)
print(plot.CA(res, axes=c(1, 2), col.row="red", col.col="blue", label=c("col", "col.sup", "row", "row.sup")))
summary(res, nb.dec = 3, nbelements=10, nbind = 10, ncp = 3, file="")
remove(Dataset.CA)
Dataset.CA<-Dataset[c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10") ,c("デザイン", "使いやすさ", "パワー", "静音性", "サイズ", "手入れのしやすさ", "取り回し",
   "満足度")]
res<-CA(Dataset.CA, ncp=5, row.sup=NULL, col.sup=NULL, graph = FALSE)
print(plot.CA(res, axes=c(1, 2), col.row="red", col.col="blue", label=c("col", "col.sup", "row", "row.sup")))
res.hcpc<-HCPC(res ,nb.clust=0,consol=FALSE,min=3,max=10,cluster.CA="rows",graph=TRUE)
summary(res, nb.dec = 3, nbelements=10, nbind = 10, ncp = 3, file="")
remove(Dataset.CA)
```

##### ▶ 一般的なRコード

`FactoMineR` パッケージをインストールしたことがなければ，最初に次のコードを実行する。
```{r}
#| eval: false
install.packages("FactoMineR")
```

その後，次のコードを実行する。
```{r}
#| echo: true
#| eval: false
library(FactoMineR)

Dataset <- read.table(file.choose(), header = TRUE, sep = "")

Dataset.CA <- Dataset[, -1]
res <- CA(Dataset.CA, ncp = 5, graph = FALSE)

plot.CA(res, axes = c(1, 2), col.row = "red", col.col = "blue")
```
```{r}
#| echo: false
#| eval: true
library(FactoMineR)

Dataset <- read.table("./data/現代マーケティング・リサーチ〔新版〕_ウェブサポートデータ/12/Cleaner.txt", header = TRUE, sep = "")

Dataset.CA <- Dataset[, -1]
res <- CA(Dataset.CA, ncp = 5, graph = FALSE)

plot.CA(res, axes = c(1, 2), col.row = "red", col.col = "blue")
```

この図のように文字化けする場合は，仕方ないと諦める。
macOSのRでは，日本語部分が文字化けしやすいと認識しておいてほしい。

```{r}
#| echo: true
#| eval: false
res.hcpc <- HCPC(res, nb.clust = 0, consol = FALSE, cluster.CA = "rows", graph = TRUE)
# plot(res.hcpc, choice = "tree")
# plot(res.hcpc, choice = "map")
```
```{r}
#| echo: false
#| eval: true
res.hcpc <- HCPC(res, nb.clust = 4, consol = FALSE, cluster.CA = "rows", graph = FALSE)
plot(res.hcpc, choice = "tree")
plot(res.hcpc, choice = "map")
```
```{r}
summary(res)
```

#### 3.2 デジタルカメラの事例

##### ▶ Rコマンダーによって生成されたコード（p. 260）

```{r}
#| eval: false
Dataset <- read.table(file.choose(), header=TRUE, stringsAsFactors=TRUE, sep="¥t", na.strings="NA", 
  dec=".", strip.white=TRUE)
Dataset.CA<-Dataset[c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10") ,c("デザイン", "画質", "操作性", "バッテリー", "携帯性", "機能性", "液晶", 
  "ホールド感", "満足度")]
res<-CA(Dataset.CA, ncp=5, row.sup=NULL, col.sup=NULL, graph = FALSE)
print(plot.CA(res, axes=c(1, 2), col.row="red", col.col="blue", label=c("col", "col.sup", "row", "row.sup")))
res.hcpc<-HCPC(res ,nb.clust=0,consol=FALSE,min=3,max=10,cluster.CA="rows",graph=TRUE)
summary(res, nb.dec = 3, nbelements=10, nbind = 10, ncp = 3, file="")
remove(Dataset.CA)
```

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: false
Dataset <- read.table(file.choose(), header = TRUE, sep = "¥t")

Dataset.CA <- Dataset[, -1]
res <- CA(Dataset.CA, ncp = 5, graph = FALSE)

plot.CA(res, axes = c(1, 2), col.row = "red", col.col = "blue")
```
```{r}
#| echo: false
#| eval: true
Dataset <- read.table("./data/現代マーケティング・リサーチ〔新版〕_ウェブサポートデータ/12/Camera.txt", header = TRUE, sep = "\t")

Dataset.CA <- Dataset[, -1]
res <- CA(Dataset.CA, ncp = 5, graph = FALSE)

plot.CA(res, axes = c(1, 2), col.row = "red", col.col = "blue")
```
```{r}
#| echo: true
#| eval: false
res.hcpc <- HCPC(res, nb.clust = 0, consol = FALSE, cluster.CA = "rows", graph = TRUE)
# plot(res.hcpc, choice = "tree")
# plot(res.hcpc, choice = "map")
```
```{r}
#| echo: false
#| eval: true
res.hcpc <- HCPC(res, nb.clust = 4, consol = FALSE, cluster.CA = "rows", graph = FALSE)
plot(res.hcpc, choice = "tree")
plot(res.hcpc, choice = "map")
```
```{r}
summary(res)
```


## 第13章 マーケットバスケットとクロスセリング

### 3 Rによるマーケットバスケット分析

##### ▶ Rコマンダーによって生成されたコード（p. 272）

```{r}
#| eval: false
y <- read.table(file.choose(), header=TRUE, stringsAsFactors=TRUE, sep=",", na.strings="NA", 
  dec=".", strip.white=TRUE)
```

##### ▶ 手入力するコード（`arules.R`）

```{r}
#| eval: false
library(arules)
class(y)
y.tran<-as(as.matrix(y),"transactions")
rules <- apriori(y.tran, parameter= list(supp=0.4, conf=0.5))
summary(rules)
inspect(head(sort(rules, by = "lift"),n=20))
```

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: false
library(arules)

y <- read.csv(file.choose(), header = TRUE)

y_tran <- as(as.matrix(y), "transactions")
class(y); class(y_tran)
```
```{r}
#| echo: false
#| eval: true
#| message: false
library(arules)

y <- read.csv("./data/現代マーケティング・リサーチ〔新版〕_ウェブサポートデータ/13/apriori.txt", header = TRUE)

y_tran <- as(as.matrix(y), "transactions")
class(y); class(y_tran)
```
```{r}
rules <- apriori(y_tran, parameter = list(supp = 0.4, conf = 0.5))
summary(rules)

inspect(head(sort(rules, by = "lift"), n = 20))
```

`rules` をデータフレームとして扱いたい場合は，次のようにするとよい。
```{r}
rules2 <- data.frame(
  lhs = labels(lhs(rules)),
  arrow = "=>",
  rhs = labels(rhs(rules)),
  quality(rules)
)

rules2[order(rules2$lift, decreasing = TRUE), ]
```


## 第14章 定性調査データの分析

### 5 顧客満足度指数：CSI

#### 5.6 Rによる顧客満足度の分析

::: {.callout-warning collapse="false" icon="false"}
## 誤植

p. 296

- （誤）(5) パス図作成のパッケージ“pathdiagram”および“DiagrammeR”をインストールする必要がある。Rのコードでは冒頭に install コマンドを記載している。
- （正）(5) パス図作成のパッケージ“DiagrammeR”をインストールする必要がある。
:::

##### ▶ 手入力するコード（`SEM-CSI-Cor.R`）

```{r}
#| eval: false
library(sem) #ライブラリの読み込み

#データの読み込み#
co <- readMoments(
  diag=TRUE, 
  names=c(
    "y01", "y02", "y03", "y04", "y05", "y06", 
    "y07", "y08", "y09", "y10"
  )
)
1
0.836 1
0.788 0.841 1
0.532 0.569 0.646 1
0.459 0.420 0.378 0.318 1
0.597 0.625 0.714 0.597 0.482 1
0.608 0.639 0.681 0.604 0.454 0.708 1
0.762 0.790 0.821 0.645 0.343 0.662 0.647 1
0.629 0.597 0.666 0.570 0.271 0.563 0.588 0.741 1
0.660 0.581 0.663 0.472 0.436 0.626 0.612 0.694 0.736 1




#モデルの作成#

#測定方程式
model <- specifyModel()
  知覚品質 -> y01, NA,  1　      #測定方程式, 識別性制約のため係数を１に固定
  知覚品質 -> y02, b12, NA
  知覚品質 -> y03, b13, NA
  知覚品質 -> y04, b14, NA
  顧客期待 -> y05, NA,  1
  顧客期待 -> y06, b22, NA
  顧客期待 -> y07, b23, NA
  顧客満足 -> y08, NA, 1
  顧客満足 -> y09, b32, NA
  顧客満足 -> y10, b33, NA
  y01 <-> y01, e01, NA　　　      #測定方程式の分散設定
  y02 <-> y02, e02, NA
  y03 <-> y03, e03, NA
  y04 <-> y04, e04, NA
  y05 <-> y05, e05, NA
  y06 <-> y06, e06, NA
  y07 <-> y07, e07, NA
  y08 <-> y08, e08, NA
  y09 <-> y09, e09, NA
  y10 <-> y10, e10, NA
  知覚品質     -> 顧客満足,  b1,NA    　　　#構造方程式
  顧客期待     -> 顧客満足,  b2,NA
  顧客期待     -> 知覚品質,  b4,NA
  知覚品質    <-> 知覚品質 , NA, 1            #構造方程式の分散設定
  顧客期待    <-> 顧客期待 , NA, 1
  顧客満足    <-> 顧客満足 , NA, 1

#分析と出力#
result <- sem(model,co,N=100) #モデル,相関係数, サンプル数の並び
summary(result,
        fit.indices = c("GFI", "AGFI", "RMSEA","NFI", "NNFI",
                        "CFI", "RNI", "IFI", "SRMR", "AIC",
                        "AICc", "BIC", "CAIC"))
stdCoef(result)　　 #標準解の表示

#パス図の作成#
pathDiagram(result, out.file="csi100-10.txt", ignore.double=FALSE, 
edge.labels="values", digits=3,
node.font=c("C:/WINDOWS/Fonts/msgothic.ttc",10)) 
```

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: true
#| message: false
library(sem)

co <- readMoments(diag = TRUE,
                  names = paste0("y", sprintf("%02d", 1:10)),
                  text = "
1
0.836 1
0.788 0.841 1
0.532 0.569 0.646 1
0.459 0.420 0.378 0.318 1
0.597 0.625 0.714 0.597 0.482 1
0.608 0.639 0.681 0.604 0.454 0.708 1
0.762 0.790 0.821 0.645 0.343 0.662 0.647 1
0.629 0.597 0.666 0.570 0.271 0.563 0.588 0.741 1
0.660 0.581 0.663 0.472 0.436 0.626 0.612 0.694 0.736 1
")

model <- specifyModel(text = "
  知覚品質 -> y01, NA,  1
  知覚品質 -> y02, b12, NA
  知覚品質 -> y03, b13, NA
  知覚品質 -> y04, b14, NA
  顧客期待 -> y05, NA,  1
  顧客期待 -> y06, b22, NA
  顧客期待 -> y07, b23, NA
  顧客満足 -> y08, NA,  1
  顧客満足 -> y09, b32, NA
  顧客満足 -> y10, b33, NA
  y01 <-> y01, e01, NA
  y02 <-> y02, e02, NA
  y03 <-> y03, e03, NA
  y04 <-> y04, e04, NA
  y05 <-> y05, e05, NA
  y06 <-> y06, e06, NA
  y07 <-> y07, e07, NA
  y08 <-> y08, e08, NA
  y09 <-> y09, e09, NA
  y10 <-> y10, e10, NA
  知覚品質   -> 顧客満足, b1, NA
  顧客期待   -> 顧客満足, b2, NA
  顧客期待   -> 知覚品質, b4, NA
  知覚品質  <-> 知覚品質, NA, 1
  顧客期待  <-> 顧客期待, NA, 1
  顧客満足  <-> 顧客満足, NA, 1
")

result <- sem(model, S = co, N = 100)
summary(result,
        fit.indices = c("GFI", "AGFI", "RMSEA","NFI", "NNFI",
                        "CFI", "RNI", "IFI", "SRMR", "AIC",
                        "AICc", "BIC", "CAIC"))
stdCoef(result)

pathDiagram(result, file = "csi100-10", output.type = "graphics", graphics.fmt = "pdf", ignore.double = FALSE, edge.labels = "values", digits = 3)
```
```{r}
#| echo: false
library(DiagrammeR)
d <- pathDiagram(result, ignore.double = FALSE, edge.labels = "values", digits = 3)
grViz(d)
```

コード `SEM-CSI-Cor.R` に記載されている `pathDiagram()` の引数 `out.file` は，関数のヘルプには見当たらない。
このような違いが生じるのは，本書で使用されている関数のバージョンが古く，現在のバージョンではその引数が廃止されたためであると考えられる。

上の `pathDiagram()` を実行すると，作業ディレクトリに `csi100-10.dot` という名前の DOT 言語によるファイルと，PDF形式のファイルが作成される。
ただし，PDFファイルでは日本語が文字化けする場合があるため注意が必要である。
DOT 言語はグラフ構造を記述するための言語であり，[Graphviz](https://www.graphviz.org/) という作図ソフトウェアを用いて図として描画できる。
DOT ファイルの中身はテキスト形式で記述されており，このファイルの中の日本語が文字化けする可能性は低い。

また，`pathDiagram()` によって作成される図は，図14.11とは異なるレイアウトで表示される。
この問題に対応するためには，例えば，`pathDiagram()` の引数 `dot.options` を次のように指定するとよい。
```{r}
pathDiagram(result, file = "csi100-10_circo", output.type = "graphics", graphics.fmt = "png", dot.options = "-Gcharset=UTF-8 -Kcirco", ignore.double = FALSE, edge.labels = "values", digits = 3)
```
![](csi100-10_circo.png)

なお，作図自体は必ずしもR上で行う必要はない。
例えば，DOT 言語のファイルに対して，コマンドプロンプト（macOS の場合は `ターミナル.app`）で以下のコマンドを実行する。
```bash
circo -Tpdf csi100-10.dot -o csi100-10.pdf
```
または
```bash
circo -Tpng csi100-10.dot -o csi100-10.png
```
これらのコマンドにより，次の図のファイルが得られる。
![](csi100-10.png)

また，次のように，`semPlot` パッケージを用いる方法もある。
```{r}
#| warning: false
library(semPlot)
semPaths(result, layout = "circle", whatLabels = "std")
```

### 6 高次因子分析

#### 6.2 Rによるサービス品質の分析

##### ▶ 手入力するコード（`SERVQUAL.R`）

```{r}
#| eval: false
library(sem)

#データの読み込み#
cor <- readMoments(names = c("y1", "y2", "y3", "y4","y5", "y6","y7", "y8", "y9", "y10"
))
1.00
0.76 1.00
0.39 0.32 1.00
0.48 0.39 0.68 1.00
0.46 0.28 0.33 0.45 1.00
0.40 0.45 0.37 0.40 0.72 1.00
0.23 0.37 0.42 0.31 0.37 0.47 1.00
0.31 0.39 0.34 0.34 0.42 0.47 0.81 1.00
0.48 0.23 0.30 0.31 0.33 0.40 0.44 0.48 1.00
0.38 0.23 0.40 0.31 0.33 0.30 0.44 0.48 0.80 1.00

#モデルの作成#

#測定方程式
　　#ラベル
model <- specifyModel()
知覚品質 -> 信頼性, a1, NA #2次因子
知覚品質 -> 有形性, a2, NA
知覚品質 -> 応答性, a3, NA
知覚品質 -> 保証性, a4, NA
知覚品質 -> 共感性, a5, NA
信頼性 -> y1, NA, 1     #1次因子
信頼性 -> y2, b1, NA
有形性 -> y3, NA, 1
有形性 -> y4, b2, NA
応答性 -> y5, NA, 1
応答性 -> y6, b3, NA
保証性 -> y7, NA, 1
保証性 -> y8, b4, NA
共感性 -> y9, NA, 1
共感性 -> y10, b5, NA
知覚品質 <-> 知覚品質, NA, 1
信頼性   <-> 信頼性, d2, NA
有形性   <-> 有形性, d3, NA
応答性   <-> 応答性, d4, NA
保証性   <-> 保証性, d5, NA
共感性   <-> 共感性, d6, NA
y1 <-> y1, e1, NA
y2 <-> y2, e2, NA
y3 <-> y3, e3, NA
y4 <-> y4, e4, NA
y5 <-> y5, e5, NA
y6 <-> y6, e6, NA
y7 <-> y7, e7, NA
y8 <-> y8, e8, NA
y9 <-> y9, e9, NA
y10 <-> y10, e10, NA

#分析と出力#
y.sem <- sem(model, cor, N = 100)
summary(y.sem,
        fit.indices = c("GFI", "AGFI", "RMSEA","NFI", "NNFI",
                        "CFI", "RNI", "IFI", "SRMR", "AIC",
                        "AICc", "BIC", "CAIC"))

#パス図の作成#
pathDiagram(y.sem, out.file="servqual.txt", ignore.double=FALSE, 
edge.labels="values", digits=3,
node.font=c("C:/WINDOWS/Fonts/msgothic.ttc",10)) 
```

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: true
#| message: false
library(sem)

cor <- readMoments(names = paste0("y", 1:10),
                   text = "
1.00
0.76 1.00
0.39 0.32 1.00
0.48 0.39 0.68 1.00
0.46 0.28 0.33 0.45 1.00
0.40 0.45 0.37 0.40 0.72 1.00
0.23 0.37 0.42 0.31 0.37 0.47 1.00
0.31 0.39 0.34 0.34 0.42 0.47 0.81 1.00
0.48 0.23 0.30 0.31 0.33 0.40 0.44 0.48 1.00
0.38 0.23 0.40 0.31 0.33 0.30 0.44 0.48 0.80 1.00
")

model <- specifyModel(text = "
知覚品質 -> 信頼性, a1, NA
知覚品質 -> 有形性, a2, NA
知覚品質 -> 応答性, a3, NA
知覚品質 -> 保証性, a4, NA
知覚品質 -> 共感性, a5, NA
信頼性 -> y1, NA, 1
信頼性 -> y2, b1, NA
有形性 -> y3, NA, 1
有形性 -> y4, b2, NA
応答性 -> y5, NA, 1
応答性 -> y6, b3, NA
保証性 -> y7, NA, 1
保証性 -> y8, b4, NA
共感性 -> y9, NA, 1
共感性 -> y10, b5, NA
知覚品質 <-> 知覚品質, NA, 1
信頼性   <-> 信頼性, d2, NA
有形性   <-> 有形性, d3, NA
応答性   <-> 応答性, d4, NA
保証性   <-> 保証性, d5, NA
共感性   <-> 共感性, d6, NA
y1 <-> y1, e1, NA
y2 <-> y2, e2, NA
y3 <-> y3, e3, NA
y4 <-> y4, e4, NA
y5 <-> y5, e5, NA
y6 <-> y6, e6, NA
y7 <-> y7, e7, NA
y8 <-> y8, e8, NA
y9 <-> y9, e9, NA
y10 <-> y10, e10, NA
")

y_sem <- sem(model, S = cor, N = 100)
summary(y_sem,
        fit.indices = c("GFI", "AGFI", "RMSEA","NFI", "NNFI",
                        "CFI", "RNI", "IFI", "SRMR", "AIC",
                        "AICc", "BIC", "CAIC"))

pathDiagram(y_sem, ignore.double = FALSE, edge.labels = "values", digits = 3)
```
```{r}
#| echo: false
d <- pathDiagram(y_sem, ignore.double = FALSE, edge.labels = "values", digits = 3)
grViz(d)
```

::: {.callout-warning collapse="false" icon="false"}
## 誤植

p. 311

- （誤）イルカ
- （正）カイル
:::


## 第15章 Eコマースとテキスト解析

### 2 テキストデータの取得と前処理

#### 2.2 Rによるスクレイピングと形態素解析

##### ▶ 手入力するコード（`scraping.R`）

```{r}
#| eval: false
##############
# テキストスクレイピングおよび前処理ーTwitterデータを例として

#①パッケージのインストール
#install.packages('rtweet', 'tidyverse')
# （以下，省略）
```

##### ▶ 一般的なRコード

`rtweet` パッケージは現在 CRAN から削除されているため，引数を指定せずに `install.packages()` を実行してもインストールできない。
どうしても使用したい場合は，バージョン `2.0.0` が最新であるようなので，調べてインストールしてほしい。
なお，未確認ではあるが，Twitter API はすでに利用できなくなっている可能性が高く，`rtweet` を用いた Twitter（X） からのデータ取得（スクレイピング）は現在では困難と考えられる。


### 3 テキストの可視化

#### 3.2 RによるワードクラウドとN-gramネットワーク

##### ▶ 手入力するコード（`wordcloud.R`）

```{r}
#| eval: false
####### ワードクラウド


# RMecabで形態素解析
# 1)　https://taku910.github.io/mecab/  <-ここでMecabの最新バージョンをダウンロード
# 2)  install.packages("RMeCab", repos = "http://rmecab.jp/R", type = "source")1

library(RMeCab)
library(ggplot2)
library(dplyr)

#①保存されたデータの読み込み
cleaned_texts <- read.csv('cleaned_text.csv',fileEncoding = 'shift-jis',row.names = 1)
cleaned_texts %>% head()
# （以下，省略）
```

##### ▶ 一般的なRコード

まず，[MeCab: Yet Another Part-of-Speech and Morphological Analyzer](https://taku910.github.io/mecab/#install){target="_blank"} の指示に従って，パソコンに MeCab をインストールする。

続いて，[RMeCab](https://rmecab.jp/wiki/index.php?RMeCab){target="_blank"} の指示に従って，R に RMeCab をインストールする。

本章では，Rコマンダーを使用しないため，一般的なRコードは省略する。

### 5 Rによる商品レビューコメントを用いた製品評価

##### ▶ 手入力するコード（`LDA.R`）

```{r}
#| eval: false
### LDA(トピックモデル)
#①パッケージ"lda"のインストール
# install.packages("lda")
library(lda)
# （以下，省略）
```

##### ▶ 一般的なRコード

本章では，Rコマンダーを使用しないため，一般的なRコードは省略する。


## 第16章 カウントデータの分析

### 4 カウントデータを用いた市場反応分析

#### 4.1 事例データ：入力データ

##### ▶ Rコマンダーによって生成されたコード（p. 330）

```{r}
#| eval: false
Dataset <- read.table(file.choose(), header=TRUE, 
  stringsAsFactors=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE)
with(Dataset, Hist(y, scale="frequency", breaks="Sturges", col="darkgray"))
```

##### ▶ 一般的なRコード

```{r}
#| echo: true
#| eval: false
Dataset <- read.csv(file.choose())

hist(Dataset$y)
```
```{r}
#| echo: false
#| eval: true
Dataset <- read.csv("./data/現代マーケティング・リサーチ〔新版〕_ウェブサポートデータ/16/count-data.csv")

hist(Dataset$y, breaks = min(Dataset$y):max(Dataset$y), main = "", xlab = "y")
```

#### 4.2 モデルによる分析

##### ▶ Rコマンダーによって生成されたコード（p. 332）

```{r}
#| eval: false
Model1 <- glm(y ~ x1 + x2 + x3 + x4 + x5 + x6, family=poisson(log), data=Dataset)
summary(Model1)
exp(coef(Model1))  # Exponentiated coefficients
Model2 <- glm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + offset(log(k)), family=poisson(log), data=Dataset)
summary(Model2)
exp(coef(Model2))  # Exponentiated coefficients
```

##### ▶ 一般的なRコード

```{r}
Model1 <- glm(y ~ x1 + x2 + x3 + x4 + x5 + x6, family = poisson(log), data = Dataset)
summary(Model1)

Model2 <- glm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + offset(log(k)), family = poisson(log), data = Dataset)
summary(Model2)
```

##### ▶ 手入力するコード（`NBR.R`）

```{r}
#| eval: false
#負の二項回帰で用いるパッケージ「MASS」を読み込む.
library(MASS)
#ポアソン回帰モデル（オフセット変数無）のコマンド．教科書ではRコマンダー実施している．
#Model1 <- glm(y ~ x1 + x2 + x3 + x4 + x5 + x6, family=poisson(log),data=Dataset)
#summary(Model1)
#ポアソン回帰モデル（オフセット変数有）のコマンド．教科書ではRコマンダー実施している．
#Model2 <- glm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + offset(log(k)),family=poisson(log), data=Dataset)
#summary(Model2)
#負の二項回帰モデル（オフセット変数無）のコマンド．
Model3 <- glm.nb(y ~ x1 + x2 + x3 + x4 + x5 + x6, link=log,data=Dataset)
summary(Model3)
#負の二項回帰モデル（オフセット変数有）のコマンド．
Model4 <- glm.nb(y ~ x1 + x2 + x3 + x4 + x5 + x6 + offset(log(k)), link=log,data=Dataset)
summary(Model4)
```

##### ▶ 一般的なRコード

```{r}
#| message: false
library(MASS)

Model3 <- glm.nb(y ~ x1 + x2 + x3 + x4 + x5 + x6, link = log, data = Dataset)
summary(Model3)

Model4 <- glm.nb(y ~ x1 + x2 + x3 + x4 + x5 + x6 + offset(log(k)), link = log, data = Dataset)
summary(Model4)
```
